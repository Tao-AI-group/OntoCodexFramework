from typing import Dict, Any, Optional, List
import os, time
from rdflib.namespace import RDFS, RDF, XSD, Namespace
from rdflib import URIRef, Literal

PROV = Namespace("http://www.w3.org/ns/prov#")
OCXP = Namespace("http://ontocodex.ai/prov#")  # custom: ocxp:confidenceScore

TEMPLATE_PY = """# Auto-generated by OntoCodex EnrichmentScriptAgent (provenance-enabled)
from rdflib import Graph, URIRef, Literal, Namespace
from rdflib.namespace import RDF, RDFS, XSD
PROV = Namespace("http://www.w3.org/ns/prov#")
OCXP = Namespace("http://ontocodex.ai/prov#")

g = Graph()
g.bind("prov", PROV)
g.bind("ocxp", OCXP)
g.bind("rdfs", RDFS)

g.parse("{doid_path}")  # load existing ontology

# --- Proposed additions with provenance ---
{triples}

g.serialize(destination="{out_ttl}", format="turtle")
print("Saved:", "{out_ttl}")
"""

def _add_assertion(subject: str, predicate: str, obj: str, prov: Dict[str, Any], idx: int) -> List[str]:
    lines: List[str] = []
    subj = subject
    pred = predicate
    assertion_id = f":assertion_{idx}"
    obj_is_literal = prov.get("object_is_literal", False)

    # Core triple
    if obj_is_literal:
        lines.append(f'g.add((URIRef("{subj}"), URIRef("{pred}"), Literal("{obj}")))')
    else:
        lines.append(f'g.add((URIRef("{subj}"), URIRef("{pred}"), URIRef("{obj}")))')

    # Provenance node
    lines.append(f'g.add((URIRef("{assertion_id}"), RDF.type, PROV.Entity))')
    src_uri = prov.get("source_uri")
    if src_uri:
        lines.append(f'g.add((URIRef("{assertion_id}"), PROV.wasDerivedFrom, URIRef("{src_uri}")))')
    agent = prov.get("agent","OntoCodexAgent")
    lines.append(f'g.add((URIRef("{assertion_id}"), PROV.wasAttributedTo, URIRef(":{agent}")))')
    ts = prov.get("timestamp")
    if ts:
        lines.append(f'g.add((URIRef("{assertion_id}"), PROV.generatedAtTime, Literal("{ts}", datatype=XSD.dateTime)))')
    ev = prov.get("evidence")
    if ev:
        safe = ev.replace("\\","\\\\").replace("\n"," ").replace('"', "\\\"")
        lines.append(f'g.add((URIRef("{assertion_id}"), PROV.value, Literal("{safe}")))')
    conf = prov.get("confidence")
    if conf is not None:
        lines.append(f'g.add((URIRef("{assertion_id}"), OCXP.confidenceScore, Literal({float(conf)}, datatype=XSD.float)))')
    return lines

class EnrichmentScriptAgent:
    def __init__(self, data_dir: str, memory):
        self.data_dir = data_dir
        self.memory = memory

    def _triples_from_relations(self, focus_iri: str, relations: List[Dict[str,Any]]) -> List[str]:
        lines: List[str] = []
        for i, rel in enumerate(relations, start=1):
            predicate = "http://purl.obolibrary.org/obo/RO_0002302" if rel["predicate"] == "treated_with" else f"http://ontocodex.ai/rel#{rel["predicate"]}"
            obj = rel["object"]
            obj_is_iri = (":" in obj or obj.startswith("http://") or obj.startswith("https://"))
            prov = {
                "source_uri": rel.get("source_uri"),
                "evidence": rel.get("evidence"),
                "agent": rel.get("agent", "KnowledgebaseAgent"),
                "timestamp": rel.get("timestamp"),
                "confidence": rel.get("confidence"),
                "object_is_literal": not obj_is_iri
            }
            obj_term = obj
            lines.extend(_add_assertion(focus_iri, predicate, obj_term, prov, idx=i))
        return lines

    def generate(self, ontology_context: Dict[str,Any], evidence: Dict[str,Any], mappings: Dict[str,Any], user_goal: str, disease_or_class: Optional[str] = None) -> Dict[str, Any]:
        doid_path = os.path.join(self.data_dir, "DOID.owl")
        ts = int(time.time())
        out_py = f"ontology_updates/auto_enrich_prov_{ts}.py"
        out_ttl = f"ontology_updates/auto_enrich_prov_{ts}.ttl"
        os.makedirs("ontology_updates", exist_ok=True)

        focus_iri = ontology_context.get("focus_iri") or "http://example.org/onto#Focus"
        rels = evidence.get("relations", [])

        triple_lines = self._triples_from_relations(focus_iri, rels)
        if not triple_lines:
            triple_lines = [f'# No relations extracted for {focus_iri}']

        py_code = TEMPLATE_PY.format(doid_path=doid_path, out_ttl=out_ttl, triples="\n".join(triple_lines))

        with open(out_py, "w", encoding="utf-8") as f:
            f.write(py_code)

        return {"script_path": out_py, "ttl_out": out_ttl, "triples_py": triple_lines, "summary": f"Generated {len(triple_lines)} statements with provenance"}
